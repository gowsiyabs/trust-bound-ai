# Environment Variables – AI Trust Lab
# Copy this file to .env and fill in your values.

# ============================================================================
# QUICK START – OpenAI (recommended, cost-efficient)
# ============================================================================
# Uncomment all four lines below and set your key:
#
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# EMBEDDING_PROVIDER=openai
# OPENAI_API_KEY=sk-your-key-here
#
# Cost estimate for 10 × 10-K files:
#   Preprocessing strips ~50-70% of raw text before embedding.
#   Embedding  (text-embedding-3-small): ~$0.01-0.05 total for initial index
#   Generation (gpt-4o-mini, 100 queries, top-k=5): ~$0.05-0.20 total
#   Use Batch API (scripts/embed_batch.py) to cut embedding cost by 50%.

# ============================================================================
# LLM PROVIDER
# ============================================================================
# Options: "ollama" (local, free) or "openai" (cloud, paid)
LLM_PROVIDER=ollama

# Model name. Leave blank to use the provider default.
#   Ollama examples : llama3.2  llama3.1  mistral  phi3
#   OpenAI examples : gpt-4o-mini  gpt-4o  gpt-3.5-turbo
LLM_MODEL=llama3.2

# ── Ollama (local) ───────────────────────────────────────────────────────────
OLLAMA_BASE_URL=http://127.0.0.1:11434

# ── OpenAI (cloud) ───────────────────────────────────────────────────────────
# OPENAI_API_KEY=sk-...

# ============================================================================
# EMBEDDING PROVIDER
# ============================================================================
# Options: "openai" or "huggingface"
# If not set, auto-detected: openai when OPENAI_API_KEY is present, else huggingface.
#
# EMBEDDING_PROVIDER=openai
#
# OpenAI embedding model (used when EMBEDDING_PROVIDER=openai):
#   text-embedding-3-small  ← recommended ($0.020 / 1M tokens)
#   text-embedding-3-large  ← higher quality ($0.130 / 1M tokens)
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
#
# Optional: reduce vector dimensions to cut storage cost (e.g. 512 instead of 1536):
# OPENAI_EMBEDDING_DIMENSIONS=512

# ============================================================================
# Application Settings
# ============================================================================
LOG_LEVEL=INFO
ENVIRONMENT=development  # development, staging, production

# ============================================================================
# Vector Store
# ============================================================================
CHROMA_PERSIST_DIR=./data/processed/embeddings

# Qdrant (if using cloud)
# QDRANT_URL=https://your-cluster.qdrant.io
# QDRANT_API_KEY=your_qdrant_api_key_here

# ============================================================================
# Safety & Monitoring
# ============================================================================
ENABLE_INPUT_VALIDATION=true
ENABLE_OUTPUT_FILTERING=true
ENABLE_PII_DETECTION=true

# ============================================================================
# Data Paths (override defaults if needed)
# ============================================================================
# DATA_DIR=./data
# DOCS_DIR=./data/documents
# EVAL_DATASETS_DIR=./data/eval_datasets
